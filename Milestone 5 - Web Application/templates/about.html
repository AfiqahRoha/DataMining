<!-- extend from base layout -->
{% extends "base.html" %}

{% block content %}
<title>Simple tables</title>

  <div class=page>
    <h1>Evaluation of Models</h1>

    <h2>Confusion Matrix</h2>
    <p>A confusion matrix is a table that is often used to describe the performance of a classification model <br>
      (or "classifier") on a set of test data for which the true values are known. The columns are the predictions <br>
      and the rows are the actual values. The main diagonal gives the correct predictions. That is, the cases where <br>
      the actual values and the model predictions are the same.
    </p>
    {% for table in tables1 %}
      <h3>{{titles1[loop.index]}}</h3>
      {{ table|safe }}
    {% endfor %}

    <h2>Classification Report</h2>
    <p>A Classification report is used to measure the quality of predictions from a classification algorithm. <br>
      How many predictions are True and how many are False. More specifically, True Positives, False Positives, <br>
      True negatives and False Negatives are used to predict the metrics of a classification report.
    </p>
    {% for table in tables2 %}
      <h3>{{titles2[loop.index]}}</h3>
      {{ table|safe }}
    {% endfor %}

  </div>
{% endblock %}